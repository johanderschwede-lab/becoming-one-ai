#!/usr/bin/env python3
"""
Complete Becoming One‚Ñ¢ Content Pipeline
======================================

Unified system that handles the complete workflow:
1. Transcription: Audio/Video ‚Üí Text
2. INBOX Processing: Text ‚Üí Knowledge Base + Content Suggestions
3. Monitoring: Real-time status of both systems

Usage:
    python start_complete_pipeline.py /path/to/inbox --transcription-method api
    python start_complete_pipeline.py /path/to/inbox --media-folder /path/to/recordings
"""

import os
import sys
import asyncio
import argparse
from pathlib import Path
from dotenv import load_dotenv
import time

# Load environment variables
load_dotenv('config/live.env')

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.core.inbox_processor import InboxProcessor
from src.core.transcription_system import TranscriptionPipeline, TranscriptionMethod


class CompletePipeline:
    """Manages both transcription and INBOX processing"""
    
    def __init__(self, inbox_folder: str, transcription_method: TranscriptionMethod = TranscriptionMethod.OPENAI_WHISPER_API):
        self.inbox_folder = Path(inbox_folder)
        self.transcription_method = transcription_method
        
        # Initialize components
        self.inbox_processor = InboxProcessor(str(self.inbox_folder))
        self.transcription_pipeline = TranscriptionPipeline(
            method=transcription_method,
            inbox_folder=str(self.inbox_folder)
        )
        
        # Create media folder for monitoring
        self.media_folder = self.inbox_folder.parent / "media_recordings"
        self.media_folder.mkdir(exist_ok=True)
        
        print(f"üìÅ INBOX: {self.inbox_folder}")
        print(f"üéµ Media folder: {self.media_folder}")
        print(f"üîß Transcription: {transcription_method.value}")
    
    async def start_complete_system(self, media_folder: str = None, process_existing: bool = False):
        """Start both transcription monitoring and INBOX processing"""
        
        print("\nüöÄ Starting Complete Becoming One‚Ñ¢ Pipeline")
        print("="*60)
        print("WORKFLOW:")
        print("1. Drop media files ‚Üí Auto-transcription")
        print("2. Transcripts ‚Üí INBOX ‚Üí AI processing")
        print("3. Teaching content ‚Üí Knowledge base")
        print("4. Community content ‚Üí Organized storage")
        print("5. Content suggestions ‚Üí Generated automatically")
        print("="*60)
        
        # Use provided media folder or default
        if media_folder:
            self.media_folder = Path(media_folder)
        
        # Process existing files if requested
        if process_existing:
            await self._process_existing_content()
        
        # Start INBOX processor in background
        print(f"\nüëÅÔ∏è  Starting INBOX processor...")
        inbox_task = asyncio.create_task(self._run_inbox_processor())
        
        # Start media folder monitoring
        print(f"üéµ Starting media transcription monitoring...")
        media_task = asyncio.create_task(self._monitor_media_folder())
        
        # Wait for both tasks
        try:
            await asyncio.gather(inbox_task, media_task)
        except KeyboardInterrupt:
            print("\nüõë Complete pipeline stopped by user")
    
    async def _process_existing_content(self):
        """Process existing media and text files"""
        print("\nüîÑ Processing existing content...")
        
        # Process existing media files
        if self.media_folder.exists():
            await self.transcription_pipeline.process_media_folder(
                str(self.media_folder), 
                auto_inbox=True
            )
        
        # Process existing INBOX files
        existing_files = list(self.inbox_folder.glob("*"))
        processable_files = [
            f for f in existing_files 
            if f.is_file() and f.suffix.lower() in self.inbox_processor.supported_extensions
        ]
        
        if processable_files:
            print(f"üìã Found {len(processable_files)} files in INBOX to process")
            for file_path in processable_files:
                await self.inbox_processor.add_file_to_queue(str(file_path))
        
        print("‚úÖ Existing content processing initiated")
    
    async def _run_inbox_processor(self):
        """Run INBOX processor"""
        try:
            # Start the processor (this blocks)
            self.inbox_processor.start_watching()
        except Exception as e:
            print(f"‚ùå INBOX processor error: {e}")
    
    async def _monitor_media_folder(self):
        """Monitor media folder for new recordings"""
        print(f"üëÅÔ∏è  Monitoring media folder: {self.media_folder}")
        
        # Keep track of processed files
        processed_files = set()
        
        while True:
            try:
                # Find media files
                media_files = []
                for ext in self.transcription_pipeline.transcription_engine.all_formats:
                    media_files.extend(self.media_folder.glob(f"*{ext}"))
                
                # Process new files
                new_files = [f for f in media_files if f not in processed_files]
                
                if new_files:
                    print(f"\nüéµ Found {len(new_files)} new media files")
                    
                    for media_file in new_files:
                        print(f"üîÑ Transcribing: {media_file.name}")
                        
                        try:
                            # Transcribe file
                            result = await self.transcription_pipeline.transcription_engine.transcribe_file(str(media_file))
                            
                            if result.error_message:
                                print(f"‚ùå Transcription failed: {result.error_message}")
                                continue
                            
                            # Save transcript
                            transcript_file = self.inbox_folder / f"{media_file.stem}_transcript.txt"
                            transcript_content = self.transcription_pipeline._format_transcript(result)
                            
                            with open(transcript_file, 'w', encoding='utf-8') as f:
                                f.write(transcript_content)
                            
                            print(f"‚úÖ Transcript saved: {transcript_file.name}")
                            print(f"üì• INBOX processor will handle automatically")
                            
                            # Mark as processed
                            processed_files.add(media_file)
                            
                        except Exception as e:
                            print(f"‚ùå Error processing {media_file.name}: {e}")
                
                # Wait before checking again
                await asyncio.sleep(10)  # Check every 10 seconds
                
            except Exception as e:
                print(f"‚ùå Media monitoring error: {e}")
                await asyncio.sleep(30)  # Wait longer on error


def show_pipeline_overview():
    """Show complete pipeline overview"""
    print("""
üîÑ COMPLETE BECOMING ONE‚Ñ¢ CONTENT PIPELINE

WORKFLOW:
1. Record workshop/interview/session (any device)
2. Drop recording in media folder ‚Üí Auto-transcription  
3. Transcript ‚Üí INBOX ‚Üí AI processing
4. Teaching content ‚Üí Knowledge base (searchable)
5. Community content ‚Üí Organized storage
6. Social media suggestions ‚Üí Generated automatically

FOLDER STRUCTURE:
üìÅ Your NAS/
‚îú‚îÄ‚îÄ media_recordings/     ‚Üê Drop .mp4/.mp3 files here
‚îú‚îÄ‚îÄ INBOX/               ‚Üê Auto-generated transcripts appear here
‚îú‚îÄ‚îÄ INBOX/completed/     ‚Üê Successfully processed files
‚îú‚îÄ‚îÄ INBOX/content_suggestions/ ‚Üê Social media content ready
‚îî‚îÄ‚îÄ INBOX/logs/          ‚Üê Processing history

TRANSCRIPTION OPTIONS:
‚Ä¢ API (default): Highest quality, ~$0.006/minute
‚Ä¢ Local: Free, requires setup (pip install openai-whisper)  
‚Ä¢ Hybrid: Smart choice per file

SUPPORTED FORMATS:
‚Ä¢ Audio: .mp3, .wav, .m4a, .flac, .ogg
‚Ä¢ Video: .mp4, .mov, .avi, .mkv (audio extracted)

WHAT HAPPENS AUTOMATICALLY:
‚úÖ Audio/video ‚Üí High-quality transcript
‚úÖ Johan/Marianne content ‚Üí Teaching materials (knowledge base)
‚úÖ Participant content ‚Üí Community insights
‚úÖ Concepts extracted ‚Üí Emotional anchors, feeling-states, etc.
‚úÖ Social content generated ‚Üí TikTok, Instagram, Twitter ready
‚úÖ Files organized ‚Üí Completed/failed folders
‚úÖ Processing logged ‚Üí Full audit trail

TIME SAVINGS:
‚Ä¢ Manual workflow: 4-6 hours per hour of content
‚Ä¢ Automated pipeline: 5-10 minutes per hour of content
‚Ä¢ ROI: Immediate after first workshop processed
    """)


async def main():
    """Main CLI function"""
    parser = argparse.ArgumentParser(
        description="Complete Becoming One‚Ñ¢ Content Processing Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python start_complete_pipeline.py /Volumes/NAS/BecomingOne/INBOX
    python start_complete_pipeline.py /path/to/inbox --transcription-method local
    python start_complete_pipeline.py /path/to/inbox --media-folder /path/to/recordings
    python start_complete_pipeline.py --show-overview
        """
    )
    
    parser.add_argument("inbox_folder", nargs="?", help="Path to INBOX folder")
    parser.add_argument("--transcription-method", 
                       choices=["api", "local", "hybrid"],
                       default="api",
                       help="Transcription method (default: api)")
    parser.add_argument("--media-folder", help="Folder to monitor for media files")
    parser.add_argument("--process-existing", action="store_true", help="Process existing files before starting")
    parser.add_argument("--show-overview", action="store_true", help="Show pipeline overview and exit")
    
    args = parser.parse_args()
    
    # Show overview if requested
    if args.show_overview:
        show_pipeline_overview()
        return
    
    # Validate input
    if not args.inbox_folder:
        parser.print_help()
        return
    
    inbox_path = Path(args.inbox_folder)
    if not inbox_path.exists():
        print(f"‚ùå INBOX folder not found: {inbox_path}")
        print("üí° Create the folder first or check the path")
        return
    
    # Check environment
    if args.transcription_method == "api" and not os.getenv("OPENAI_API_KEY"):
        print("‚ùå OpenAI API key not found for transcription")
        print("üí° Set OPENAI_API_KEY in config/live.env or use --transcription-method local")
        return
    
    # Map method names
    method_map = {
        "api": TranscriptionMethod.OPENAI_WHISPER_API,
        "local": TranscriptionMethod.LOCAL_WHISPER,
        "hybrid": TranscriptionMethod.HYBRID
    }
    
    method = method_map[args.transcription_method]
    
    # Create and start pipeline
    try:
        pipeline = CompletePipeline(str(inbox_path), method)
        await pipeline.start_complete_system(
            media_folder=args.media_folder,
            process_existing=args.process_existing
        )
    except KeyboardInterrupt:
        print("\nüõë Pipeline stopped by user")
    except Exception as e:
        print(f"‚ùå Pipeline error: {e}")


if __name__ == "__main__":
    # Show help if no arguments
    if len(sys.argv) == 1:
        show_pipeline_overview()
        print("\nUse --help for detailed usage information")
    else:
        asyncio.run(main())
