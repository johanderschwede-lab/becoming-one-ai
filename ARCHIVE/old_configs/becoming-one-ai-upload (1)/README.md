# Becoming Oneâ„¢ AI Journey System

## Vision
Create an AI-powered omnichannel mentor system that:
1. Recognizes and adapts to users across all platforms (Telegram, YouTube, TikTok, Email, BuddyBoss, etc.)
2. Delivers personalized, evolving guidance through the Becoming Oneâ„¢ method
3. Supports Johan & Marianne in evolving the method itself as a living, co-creative Muse

## Project Structure

```
becoming-one-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ bots/              # Platform-specific bot implementations
â”‚   â”‚   â”œâ”€â”€ telegram/      # Telegram bot
â”‚   â”‚   â”œâ”€â”€ youtube/       # YouTube integration
â”‚   â”‚   â””â”€â”€ email/         # Email integration
â”‚   â”œâ”€â”€ core/              # Core AI logic and Becoming Oneâ„¢ method
â”‚   â”‚   â”œâ”€â”€ ai_engine.py   # Main AI processing
â”‚   â”‚   â”œâ”€â”€ becoming_one_method.py # Core methodology
â”‚   â”‚   â””â”€â”€ personalization.py # User adaptation logic
â”‚   â”œâ”€â”€ database/          # Database models and operations
â”‚   â”‚   â”œâ”€â”€ models.py      # Supabase models
â”‚   â”‚   â””â”€â”€ operations.py  # Database operations
â”‚   â”œâ”€â”€ integrations/      # Third-party service integrations
â”‚   â”‚   â”œâ”€â”€ pinecone_client.py # Vector search
â”‚   â”‚   â”œâ”€â”€ openai_client.py   # GPT integration
â”‚   â”‚   â””â”€â”€ make_webhooks.py   # Make.com integration
â”‚   â””â”€â”€ utils/             # Shared utilities
â”œâ”€â”€ config/                # Configuration files
â”œâ”€â”€ database/              # Database schemas and migrations
â”‚   â”œâ”€â”€ schemas/           # Supabase table schemas
â”‚   â””â”€â”€ migrations/        # Database migration scripts
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ scripts/               # Deployment and utility scripts
â””â”€â”€ tests/                 # Test files
```

## Phase 1: Foundation (August 2025)
**Goal**: Working Telegram bot with Pinecone retrieval and Supabase identity logging

### âœ… DONE:
- Telegram bot responding to queries via Make.com scenario
- Pinecone vector search integrated (context-aware)

### ðŸ”„ TO DO:
1. **Supabase Setup**
   - Create tables: identity_registry, event_log, channel_mapping
   - Enable webhooks for event inserts
   - Set up person_id enrichment for GPT prompts

2. **Make.com Modules**
   - Connect Supabase HTTP API
   - Set up Telegram message handling
   - Implement person_id lookup and content insertion

3. **Tagging & Metadata Layer**
   - Add basic tagging to events (identity, confusion, fear, etc.)
   - Store tags in metadata for Pinecone records
   - Use tag-based filtering in queries

## Tech Stack
- **Database**: Supabase (PostgreSQL)
- **Vector Search**: Pinecone
- **Automation**: Make.com
- **Platforms**: Telegram, YouTube, TikTok, Email, BuddyBoss
- **AI**: OpenAI GPT integration
- **Languages**: Python, JavaScript/Node.js

## Getting Started
1. Copy `.env.example` to `.env` and fill in your API keys
2. Install dependencies: `pip install -r requirements.txt`
3. Set up Supabase database using schemas in `database/schemas/`
4. Configure Make.com scenarios
5. Test Telegram bot integration

## Environment Variables Needed
- `SUPABASE_URL`
- `SUPABASE_ANON_KEY`
- `PINECONE_API_KEY`
- `OPENAI_API_KEY`
- `TELEGRAM_BOT_TOKEN`
- `MAKE_WEBHOOK_URL`
