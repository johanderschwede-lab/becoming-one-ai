original_path: /Users/johanniklasson/Documents/becoming-one-ai/CompassBuilder_Phase2/documents_to_process/STORAGE_STRATEGY.md
archived_at: '2025-08-19T11:18:42.092650'
status: processed
category: documentation
file_hash: 79ae7486ec4b5ef1d117f54ca7f43f6d2d9f94a48a172d2a34d83c7de16389b2
analysis_summary:
  categories:
  - content_processing
  analysis:
    content: "# \U0001F5C4\uFE0F Storage Strategy\n## Clean Data Architecture with\
      \ Supabase as Foundation\n\n### 1. Core Data Types & Their Homes\n\n#### Identity\
      \ & Core User Data (Supabase)\n```sql\n-- Already set up in Supabase\nCREATE\
      \ TABLE identity_registry (\n    person_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n\
      \    created_at TIMESTAMPTZ DEFAULT NOW(),\n    last_seen_at TIMESTAMPTZ,\n\
      \    consent_status JSONB DEFAULT '{}',\n    metadata JSONB DEFAULT '{}'\n);\n\
      \n-- Cross-platform identity links\nCREATE TABLE identity_links (\n    link_id\
      \ UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    person_id UUID REFERENCES\
      \ identity_registry(person_id),\n    platform TEXT NOT NULL,\n    platform_id\
      \ TEXT NOT NULL,\n    verified BOOLEAN DEFAULT false,\n    created_at TIMESTAMPTZ\
      \ DEFAULT NOW(),\n    UNIQUE(platform, platform_id)\n);\n```\n\n#### Interaction\
      \ Events (Supabase)\n```sql\n-- High-volume event logging\nCREATE TABLE event_log\
      \ (\n    event_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    person_id\
      \ UUID REFERENCES identity_registry(person_id),\n    event_type TEXT NOT NULL,\n\
      \    platform TEXT NOT NULL,\n    content JSONB NOT NULL,\n    metadata JSONB\
      \ DEFAULT '{}',\n    created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Add hypertable\
      \ for time-series optimization\nSELECT create_hypertable('event_log', 'created_at');\n\
      ```\n\n#### Knowledge Base (Pinecone + Supabase)\n```python\nclass KnowledgeStore:\n\
      \    def __init__(self):\n        self.pinecone = PineconeClient()  # Semantic\
      \ vectors\n        self.supabase = SupabaseClient()  # Metadata & content\n\
      \    \n    async def store_knowledge(self, content: str, metadata: dict):\n\
      \        # Get embedding\n        embedding = await self.get_embedding(content)\n\
      \        \n        # Store in Pinecone\n        vector_id = await self.pinecone.upsert(\n\
      \            vectors=[(str(uuid4()), embedding)],\n            namespace=\"\
      knowledge\"\n        )\n        \n        # Store metadata in Supabase\n   \
      \     await self.supabase.table('knowledge_items').insert({\n            'vector_id':\
      \ vector_id,\n            'content': content,\n            'metadata': metadata\n\
      \        })\n```\n\n### 2. Data Access Patterns\n\n#### Direct Queries (Supabase)\n\
      ```python\nclass IdentityService:\n    async def get_identity(self, platform:\
      \ str, platform_id: str):\n        # Direct SQL query for identity lookup\n\
      \        result = await self.supabase.rpc(\n            'get_identity_by_platform',\n\
      \            {\n                'p_platform': platform,\n                'p_platform_id':\
      \ platform_id\n            }\n        )\n        return result.data\n```\n\n\
      #### Semantic Search (Pinecone)\n```python\nclass KnowledgeService:\n    async\
      \ def search_knowledge(self, query: str, limit: int = 5):\n        # Get query\
      \ embedding\n        query_embedding = await self.get_embedding(query)\n   \
      \     \n        # Search Pinecone\n        results = await self.pinecone.query(\n\
      \            vector=query_embedding,\n            top_k=limit,\n           \
      \ namespace=\"knowledge\"\n        )\n        \n        # Get metadata from\
      \ Supabase\n        vector_ids = [r.id for r in results.matches]\n        metadata\
      \ = await self.supabase.table('knowledge_items').select(\n            '*'\n\
      \        ).in_('vector_id', vector_ids).execute()\n        \n        return\
      \ self.combine_results(results.matches, metadata)\n```\n\n#### Event Streaming\
      \ (Supabase Realtime)\n```python\nclass EventService:\n    async def subscribe_to_events(self,\
      \ person_id: UUID):\n        # Subscribe to real-time events\n        channel\
      \ = await self.supabase.channel('events')\n        channel.on(\n           \
      \ 'postgres_changes',\n            event='INSERT',\n            schema='public',\n\
      \            table='event_log',\n            filter=f\"person_id=eq.{person_id}\"\
      ,\n            callback=self.handle_event\n        )\n```\n\n### 3. Data Separation\
      \ Principles\n\n#### Identity Data (Supabase)\n- Core user information\n- Cross-platform\
      \ links\n- Consent & preferences\n- Stable, rarely changes\n\n#### Event Data\
      \ (Supabase with TimescaleDB)\n- All interactions\n- System events\n- Analytics\
      \ data\n- High volume, time-series\n\n#### Knowledge Data (Pinecone + Supabase)\n\
      - Semantic vectors in Pinecone\n- Content & metadata in Supabase\n- Cross-referenced\
      \ by vector_id\n\n### 4. Data Flow Examples\n\n#### New User Registration\n\
      ```python\nasync def register_user(platform: str, platform_id: str, metadata:\
      \ dict):\n    # Create identity\n    person_id = await identity_service.create_identity(metadata)\n\
      \    \n    # Link platform\n    await identity_service.create_link(person_id,\
      \ platform, platform_id)\n    \n    # Log event\n    await event_service.log_event(\n\
      \        person_id=person_id,\n        event_type=\"registration\",\n      \
      \  platform=platform,\n        content={\"platform_id\": platform_id}\n    )\n\
      \    \n    return person_id\n```\n\n#### Message Processing\n```python\nasync\
      \ def process_message(platform: str, message: dict):\n    # Get identity\n \
      \   identity = await identity_service.get_identity(\n        platform=platform,\n\
      \        platform_id=message['sender_id']\n    )\n    \n    # Log interaction\n\
      \    await event_service.log_event(\n        person_id=identity.person_id,\n\
      \        event_type=\"message\",\n        platform=platform,\n        content=message\n\
      \    )\n    \n    # Store as knowledge if relevant\n    if should_store_as_knowledge(message):\n\
      \        await knowledge_service.store_knowledge(\n            content=message['text'],\n\
      \            metadata={\n                'person_id': identity.person_id,\n\
      \                'platform': platform,\n                'timestamp': message['timestamp']\n\
      \            }\n        )\n```\n\n### 5. Performance Considerations\n\n####\
      \ Supabase Optimization\n```sql\n-- Add indexes for common queries\nCREATE INDEX\
      \ idx_event_log_person_type \nON event_log (person_id, event_type, created_at\
      \ DESC);\n\n-- Partition large tables\nSELECT create_hypertable(\n    'event_log',\n\
      \    'created_at',\n    chunk_time_interval => INTERVAL '1 day'\n);\n```\n\n\
      #### Pinecone Optimization\n```python\n# Batch vector operations\nasync def\
      \ batch_store_knowledge(items: List[dict]):\n    # Prepare vectors\n    vectors\
      \ = []\n    metadata = []\n    \n    for item in items:\n        embedding =\
      \ await self.get_embedding(item['content'])\n        vector_id = str(uuid4())\n\
      \        vectors.append((vector_id, embedding))\n        metadata.append({\n\
      \            'vector_id': vector_id,\n            **item['metadata']\n     \
      \   })\n    \n    # Batch insert to Pinecone\n    await self.pinecone.upsert(vectors=vectors)\n\
      \    \n    # Batch insert to Supabase\n    await self.supabase.table('knowledge_items').insert(metadata)\n\
      ```\n\nThis strategy:\n1. Uses Supabase for structured data and real-time features\n\
      2. Uses Pinecone for semantic search capabilities\n3. Keeps clear boundaries\
      \ between data types\n4. Maintains high performance at scale\n5. Supports real-time\
      \ features through Supabase\n\nEach component can evolve independently while\
      \ maintaining clean interfaces with the others.\n"
    analysis: 'TOPICS: Data Storage, Clean Data Architecture, Supabase, Core Data
      Types, Identity & Core User Data, Interaction Events, SQL


      TYPE: Technical Document/Implementation Guide


      CONCEPTS: Data Types, Data Storage, Supabase, Identity Registry, Identity Links,
      Event Logging, SQL, Database Tables


      RATIO: 80% Technical, 20% Conceptual


      DETAILS: The document provides SQL scripts for creating tables in a database.
      The tables include ''identity_registry'' and ''identity_links'' for storing
      identity and core user data, and ''event_log'' for logging interaction events.
      The ''identity_registry'' table includes fields for person_id, created_at, last_seen_at,
      consent_status, and metadata. The ''identity_links'' table includes fields for
      link_id, person_id, platform, platform_id, verified, created_at and a unique
      constraint on platform and platform_id. The ''event_log'' table''s structure
      is not fully shown.'
    analyzed_at: '2025-08-19T11:18:42.090386'
  destination: Phase1_Legacy_Imports/content_processing
size_bytes: 6770
